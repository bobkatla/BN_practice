{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing to have final data \n",
    "After annotate the meta data of census and have the samples matching\n",
    "Note, now need to process the census again to have the distribution of HH correctly, maybe remove hhinc as well. Also include the negative hhinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from PopSynthesis.Generator_data.generate_combine_census.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the meta data\n",
    "meta_df_hh = pd.read_csv(\"./processed_data/meta_data_hh_manual.csv\")\n",
    "meta_df_pp = pd.read_csv(\"./processed_data/meta_data_pp_manual.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_lev = \"POA\"\n",
    "data_raw = process_from_census_data(geo_lev=geo_lev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_cols = [x for x in data_raw.columns if \"Person_\" in x]\n",
    "hh_cols = [x for x in data_raw.columns if \"Dwelling_\" in x]\n",
    "\n",
    "pp_marg_raw = data_raw[persons_cols]\n",
    "hh_marg_raw = data_raw[hh_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_have_geo_pp = [x for x in pp_marg_raw.columns if geo_lev in x]\n",
    "assert len(cols_have_geo_pp) == 1\n",
    "tot_pp_seri = pp_marg_raw[cols_have_geo_pp[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_cols = [x for x in hh_marg_raw.columns if \"Dwelling_NPRD Number of Persons Usually Resident in Dwelling\" in x and \"Not applicable\" not in x]\n",
    "tot_hh_seri = hh_marg_raw[ls_cols].sum(axis=1) + 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_all(type_att=\"Dwelling\"):\n",
    "    if type_att == \"Dwelling\":\n",
    "        meta_data, raw_marg_data, tot_seri = meta_df_hh, hh_marg_raw, tot_hh_seri\n",
    "    elif type_att == \"Person\":\n",
    "        meta_data, raw_marg_data, tot_seri = meta_df_pp, pp_marg_raw, tot_pp_seri\n",
    "    else:\n",
    "        raise ValueError(\"No exist this type\")\n",
    "    \n",
    "    ls_df_to_concat = []\n",
    "    for att_code in meta_data[\"att_code_census\"].unique():\n",
    "        dict_hold_val = {}\n",
    "\n",
    "        sub_df = meta_data[meta_data[\"att_code_census\"]==att_code]\n",
    "        assert len(sub_df[\"att_description\"].unique()) == 1\n",
    "        assert len(sub_df[\"att_sample\"].unique()) == 1\n",
    "        \n",
    "        name_full = type_att + \"_\" + att_code + \" \" + sub_df[\"att_description\"].unique()[0]\n",
    "        att_sample = sub_df[\"att_sample\"].unique()[0]\n",
    "        all_state_census = sub_df[\"state_census\"].unique()\n",
    "        all_cols_name = [f\"{name_full}__{state_census}\" for state_census in all_state_census]\n",
    "        gb_df = sub_df.groupby(\"state_sample\")[\"state_census\"].apply(lambda x: list(x))\n",
    "\n",
    "        # Process delete all and shift the value to others cols\n",
    "        re_df = raw_marg_data.fillna(0)\n",
    "        if \"SHIFT\" in gb_df.index:\n",
    "            sub_del_name = gb_df[\"SHIFT\"]\n",
    "            cols_del = [f\"{name_full}__{del_census}\" for del_census in sub_del_name]\n",
    "            ls_not_del = list(set(all_cols_name) - set(cols_del))\n",
    "            to_plus_seri = raw_marg_data[cols_del].sum(axis=1) / len(ls_not_del)\n",
    "            re_df = raw_marg_data[ls_not_del].add(to_plus_seri, axis=\"index\")\n",
    "\n",
    "        # Process the break when we want the value to shared between specific cols\n",
    "        for att_sample_state in gb_df.index:\n",
    "            if \"BREAK\" in att_sample_state:\n",
    "                ls_cols_to_take = att_sample_state.split(\":\")[1].split(\"|\")\n",
    "                hold_cols = []\n",
    "                for x in ls_cols_to_take:\n",
    "                     hold_cols += gb_df[x]\n",
    "                col_del = f\"{name_full}__{gb_df[att_sample_state][0]}\"\n",
    "                cols_to_update = [f\"{name_full}__{col_take}\" for col_take in hold_cols]\n",
    "                sub_df_of_this = re_df[cols_to_update].add((re_df[col_del] / len(ls_cols_to_take)), axis=\"index\")\n",
    "                # Update the final df\n",
    "                re_df[cols_to_update] = sub_df_of_this\n",
    "\n",
    "        for att_sample_state in gb_df.index:\n",
    "            if \"BREAK\" not in att_sample_state and \"DELETE\" != att_sample_state and \"SHIFT\" != att_sample_state:\n",
    "                ls_of_census = [f\"{name_full}__{census_val}\" for census_val in gb_df[att_sample_state]]\n",
    "                final_seri_val = re_df[ls_of_census].sum(axis=1)\n",
    "                dict_hold_val[(att_sample, att_sample_state)] = final_seri_val\n",
    "        df_of_att = pd.DataFrame(dict_hold_val)\n",
    "        # Process to intergalised the re_df\n",
    "        after_inter = update_int_all(df_of_att, tot_seri)\n",
    "        ls_df_to_concat.append(after_inter)\n",
    "\n",
    "    final_df = pd.concat(ls_df_to_concat, axis=1)\n",
    "    final_df.insert(loc=0, column=(\"zone_id\", None), value=final_df.index)\n",
    "    if type_att == \"Dwelling\":\n",
    "        final_df.insert(loc=1, column=(\"sample_geog\", None), value=2)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_census_hh = process_data_all(type_att=\"Dwelling\")\n",
    "final_df_census_pp = process_data_all(type_att=\"Person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6464884"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = final_df_census_hh[final_df_census_hh.columns[final_df_census_hh.columns.get_level_values(0)==\"hhsize\"]]\n",
    "tem_s = 0\n",
    "for i in range(1, 8):\n",
    "    tem_s += a[(\"hhsize\", str(i))] * i\n",
    "tem_s += a[(\"hhsize\", \"8+\")] * 10\n",
    "tem_s.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6450747"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_pp_seri.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3926 [('dwelltype', 'Flat or Apartment')]\n"
     ]
    }
   ],
   "source": [
    "a = final_df_census_hh.astype(int) < 0\n",
    "dict_to_process = {}\n",
    "for i, r in a.iterrows():\n",
    "    if r.any():\n",
    "        loc_cols = r[r].index\n",
    "        dict_to_process[i] = list(loc_cols)\n",
    "\n",
    "for idx, ls_cols in dict_to_process.items():\n",
    "    print(idx, ls_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_census_hh.to_csv(\"./hh_marginals_ipu.csv\", index=False)\n",
    "final_df_census_pp.to_csv(\"./person_marginals_ipu.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the sample data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_sample_hh = pd.read_csv(\"./processed_data/ori_sample_hh.csv\")\n",
    "ori_sample_pp = pd.read_csv(\"./processed_data/ori_sample_pp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipu_sample_hh = ori_sample_hh.drop(columns=[\"Spouse\",\"Child\",\"Others\",\"Grandchild\",\"_weight\"]).rename(columns={\"hhid\": \"serialno\"})\n",
    "ipu_sample_pp = ori_sample_pp.drop(columns=[\"persid\", \"_weight\"]).rename(columns={\"hhid\": \"serialno\"})\n",
    "ipu_sample_hh.insert(loc=1, column=\"sample_geog\", value=2)\n",
    "ipu_sample_pp.insert(loc=1, column=\"sample_geog\", value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipu_sample_pp.to_csv(\"./pp_sample_ipu.csv\", index=False)\n",
    "ipu_sample_hh.to_csv(\"./hh_sample_ipu.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "popsyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
