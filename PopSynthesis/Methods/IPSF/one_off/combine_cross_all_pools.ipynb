{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all existing pools to check for shared combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from PopSynthesis.Methods.IPSF.const import (\n",
    "    HH_TAG,\n",
    "    HH_ATTS,\n",
    "    PP_ATTS,\n",
    "    NOT_INCLUDED_IN_BN_LEARN,\n",
    "    processed_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the people pools\n",
    "# Get the household pools\n",
    "# Get the paired people pools\n",
    "\n",
    "hh_pool = pd.read_csv(processed_dir / \"HH_pool.csv\")\n",
    "pp_pool = pd.read_csv(processed_dir / \"PP_pool.csv\")\n",
    "with open(processed_dir / \"dict_pool_pairs_by_layers.pickle\", \"rb\") as handle:\n",
    "    pools_ref = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Child',\n",
       " 'Grandchild',\n",
       " 'Grandparent',\n",
       " 'Main',\n",
       " 'Others',\n",
       " 'Parent',\n",
       " 'Sibling',\n",
       " 'Spouse'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rela = set(x.split(\"-\")[-1] for x in pools_ref.keys())\n",
    "all_rela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pools_ref[HH_TAG] = hh_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_atts = [x for x in PP_ATTS if x not in NOT_INCLUDED_IN_BN_LEARN]\n",
    "hh_atts = [x for x in HH_ATTS if x not in NOT_INCLUDED_IN_BN_LEARN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the people-related pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HH-Main\n",
      "Main-Spouse\n",
      "Main-Child\n",
      "Main-Parent\n",
      "Main-Sibling\n",
      "Main-Others\n",
      "Main-Grandchild\n",
      "Main-Grandparent\n",
      "Child-Grandchild\n",
      "Parent-Grandparent\n",
      "HH\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1056"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then make sure all people in pool exist in the rela pools and vice versa\n",
    "# DO this by detect all possible combinations in pools and intersect\n",
    "# DO this by decouple the paired rela pools to have possible people combs\n",
    "# If del in people pool is ez but if del for others, we must del all \n",
    "\n",
    "def combine_all_pp_comb(pools_ref):\n",
    "    possible_combs = []\n",
    "    for pair_name, paired_pool in pools_ref.items():\n",
    "        print(pair_name)\n",
    "        if HH_TAG in pair_name:\n",
    "            continue\n",
    "        root_rela, sample_rela = pair_name.split(\"-\")\n",
    "        root_atts = [f\"{x}_{root_rela}\" for x in pp_atts]\n",
    "        sample_atts = [f\"{x}_{sample_rela}\" for x in pp_atts]\n",
    "        root_filtered_combs = set(paired_pool.set_index(root_atts).index)\n",
    "        sample_filtered_combs = set(paired_pool.set_index(sample_atts).index)\n",
    "        possible_combs.append(root_filtered_combs | sample_filtered_combs)\n",
    "    return set.union(*possible_combs)\n",
    "\n",
    "possible_pp_comb_in_pool_refs = combine_all_pp_comb(pools_ref)\n",
    "len(possible_pp_comb_in_pool_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_combs_in_pool = set(pp_pool.set_index(pp_atts).index)\n",
    "len(possible_combs_in_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_pp_combs = possible_pp_comb_in_pool_refs & possible_combs_in_pool\n",
    "len(possible_pp_combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Updating the pools\n",
    "pp_pool = pp_pool.set_index(pp_atts).loc[list(possible_pp_combs)].reset_index()\n",
    "print(pp_pool.shape)\n",
    "\n",
    "# NO LONGER DO THIS, AS WE UPDATE THE POOL ON THE WAY LATER\n",
    "# for pair_name, paired_pool in pools_ref.items():\n",
    "#     if HH_TAG in pair_name:\n",
    "#         continue\n",
    "#     root_rela, sample_rela = pair_name.split(\"-\")\n",
    "#     root_atts = [f\"{x}_{root_rela}\" for x in pp_atts]\n",
    "#     sample_atts = [f\"{x}_{sample_rela}\" for x in pp_atts]\n",
    "#     root_filtered_combs = set(paired_pool.set_index(root_atts).index)\n",
    "#     new_pool = paired_pool.set_index(root_atts).loc[list(possible_pp_combs & root_filtered_combs)].reset_index()\n",
    "#     sample_filtered_combs = set(new_pool.set_index(sample_atts).index)\n",
    "#     new_pool = new_pool.set_index(sample_atts).loc[list(possible_pp_combs & sample_filtered_combs)].reset_index()\n",
    "#     pools_ref[pair_name] = new_pool\n",
    "#     print(f\"Finish {pair_name} with shape {new_pool.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter pools rela by rela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_check_between_2_pools(pool1, pool2, considered_atts):\n",
    "    assert set(considered_atts) <= set(pool1.columns)\n",
    "    assert set(considered_atts) <= set(pool2.columns)\n",
    "    converted_pool1 = pool1.set_index(considered_atts)\n",
    "    converted_pool2 = pool2.set_index(considered_atts)\n",
    "    possible_comb = set(converted_pool1.index) & set(converted_pool2.index)\n",
    "    result_pool1 = converted_pool1.loc[list(possible_comb)].reset_index()\n",
    "    result_pool2 = converted_pool2.loc[list(possible_comb)].reset_index()\n",
    "    return result_pool1, result_pool2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['HH-Main', 'Main-Spouse', 'Main-Child', 'Main-Parent', 'Main-Sibling', 'Main-Others', 'Main-Grandchild', 'Main-Grandparent', 'Child-Grandchild', 'Parent-Grandparent', 'HH'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pools_ref[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HH-Main\n",
      "Processing Main-Spouse\n",
      "Empty DataFrame\n",
      "Columns: [age_Main, sex_Main, persinc_Main, nolicence_Main, anywork_Main, dwelltype, hhinc, hhsize, totalvehs, owndwell, Main, Spouse, Child, Parent, Sibling, Others, Grandchild, Grandparent]\n",
      "Index: []\n",
      "Processing Main-Child\n",
      "Empty DataFrame\n",
      "Columns: [age_Main, sex_Main, persinc_Main, nolicence_Main, anywork_Main, dwelltype, hhinc, hhsize, totalvehs, owndwell, Main, Spouse, Child, Parent, Sibling, Others, Grandchild, Grandparent]\n",
      "Index: []\n",
      "Processing Main-Parent\n",
      "Empty DataFrame\n",
      "Columns: [age_Main, sex_Main, persinc_Main, nolicence_Main, anywork_Main, dwelltype, hhinc, hhsize, totalvehs, owndwell, Main, Spouse, Child, Parent, Sibling, Others, Grandchild, Grandparent]\n",
      "Index: []\n",
      "Processing Main-Sibling\n",
      "Empty DataFrame\n",
      "Columns: [age_Main, sex_Main, persinc_Main, nolicence_Main, anywork_Main, dwelltype, hhinc, hhsize, totalvehs, owndwell, Main, Spouse, Child, Parent, Sibling, Others, Grandchild, Grandparent]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# So we now handling two pools only\u001b[39;00m\n\u001b[0;32m     19\u001b[0m to_consider_atts \u001b[38;5;241m=\u001b[39m hh_atts \u001b[38;5;28;01mif\u001b[39;00m root_rela\u001b[38;5;241m==\u001b[39mHH_TAG \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_rela\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m pp_atts]\n\u001b[1;32m---> 20\u001b[0m updated_prev_pool, updated_curr_pool \u001b[38;5;241m=\u001b[39m \u001b[43mcross_check_between_2_pools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaired_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_consider_atts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m other_pool\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     23\u001b[0m     updated_prev_pool \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([updated_prev_pool, other_pool], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mcross_check_between_2_pools\u001b[1;34m(pool1, pool2, considered_atts)\u001b[0m\n\u001b[0;32m      4\u001b[0m converted_pool1 \u001b[38;5;241m=\u001b[39m pool1\u001b[38;5;241m.\u001b[39mset_index(considered_atts)\n\u001b[0;32m      5\u001b[0m converted_pool2 \u001b[38;5;241m=\u001b[39m pool2\u001b[38;5;241m.\u001b[39mset_index(considered_atts)\n\u001b[1;32m----> 6\u001b[0m possible_comb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(converted_pool1\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconverted_pool2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m result_pool1 \u001b[38;5;241m=\u001b[39m converted_pool1\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlist\u001b[39m(possible_comb)]\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      8\u001b[0m result_pool2 \u001b[38;5;241m=\u001b[39m converted_pool2\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlist\u001b[39m(possible_comb)]\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mc:\\Users\\dlaa0001\\Anaconda3\\envs\\popsyn\\lib\\site-packages\\pandas\\core\\base.py:780\u001b[0m, in \u001b[0;36mIndexOpsMixin.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;124;03mReturn an iterator of the values.\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;124;03miterator\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;66;03m# We are explicitly making element iterators.\u001b[39;00m\n\u001b[1;32m--> 780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# Check type instead of dtype to catch DTA/TDA\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values)\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for pair_name, paired_pool in pools_ref.items(): # The order matters here\n",
    "    print(f\"Processing {pair_name}\")\n",
    "    if pair_name == HH_TAG:\n",
    "        continue\n",
    "\n",
    "    root_rela, sample_rela = pair_name.split(\"-\")\n",
    "    prev_pools = [x for x in pools_ref.keys() if x.split(\"-\")[-1] == root_rela]\n",
    "    assert len(prev_pools) == 1\n",
    "    prev_pool = pools_ref[prev_pools[0]]\n",
    "\n",
    "    other_pool = pd.DataFrame()\n",
    "    if sample_rela in prev_pool.columns:\n",
    "        # This happens for the case of relationships\n",
    "        prev_pool = prev_pool[prev_pool[sample_rela] > 0]\n",
    "        other_pool = prev_pool[prev_pool[sample_rela] == 0]\n",
    "        print(other_pool)\n",
    "\n",
    "    # So we now handling two pools only\n",
    "    to_consider_atts = hh_atts if root_rela==HH_TAG else [f\"{x}_{root_rela}\" for x in pp_atts]\n",
    "    updated_prev_pool, updated_curr_pool = cross_check_between_2_pools(prev_pool, paired_pool, to_consider_atts)\n",
    "\n",
    "    if not other_pool.empty:\n",
    "        updated_prev_pool = pd.concat([updated_prev_pool, other_pool], axis=0)\n",
    "        print(updated_prev_pool)\n",
    "\n",
    "    # print(f\"Finish {pair_name} with shape {new_pool.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pools_hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HH-Main for Main\n",
      "Processing Main-Spouse for Main\n",
      "Processing Main-Child for Main\n",
      "Processing Main-Parent for Main\n",
      "Processing Main-Sibling for Main\n",
      "Processing Main-Others for Main\n",
      "Processing Main-Grandchild for Main\n",
      "Processing Main-Grandparent for Main\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m pool \u001b[38;5;241m=\u001b[39m pools_ref[pool_name]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m converted_pool \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mset_index(considered_atts)\n\u001b[1;32m---> 20\u001b[0m pools_ref[pool_name] \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpossible_comb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mc:\\Users\\dlaa0001\\Anaconda3\\envs\\popsyn\\lib\\site-packages\\pandas\\core\\indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dlaa0001\\Anaconda3\\envs\\popsyn\\lib\\site-packages\\pandas\\core\\indexing.py:1332\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\dlaa0001\\Anaconda3\\envs\\popsyn\\lib\\site-packages\\pandas\\core\\indexing.py:1272\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1272\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1274\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dlaa0001\\Anaconda3\\envs\\popsyn\\lib\\site-packages\\pandas\\core\\indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1459\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1460\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1462\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\dlaa0001\\Anaconda3\\envs\\popsyn\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:2539\u001b[0m, in \u001b[0;36mMultiIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   2536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(key, indexer, axis_name)\n\u001b[0;32m   2537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[indexer], indexer\n\u001b[1;32m-> 2539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dlaa0001\\Anaconda3\\envs\\popsyn\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5875\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex(keyarr)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_non_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[1;32mc:\\Users\\dlaa0001\\Anaconda3\\envs\\popsyn\\lib\\site-packages\\pandas\\core\\indexes\\base.py:4318\u001b[0m, in \u001b[0;36mIndex._reindex_non_unique\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   4315\u001b[0m     \u001b[38;5;66;03m# GH#13691\u001b[39;00m\n\u001b[0;32m   4316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[:\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 4318\u001b[0m indexer, missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_non_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4319\u001b[0m check \u001b[38;5;241m=\u001b[39m indexer \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4320\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer[check])\n",
      "File \u001b[1;32mc:\\Users\\dlaa0001\\Anaconda3\\envs\\popsyn\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5813\u001b[0m, in \u001b[0;36mIndex.get_indexer_non_unique\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   5811\u001b[0m pself, ptarget \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_promote(target)\n\u001b[0;32m   5812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pself \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m ptarget \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target:\n\u001b[1;32m-> 5813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpself\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_non_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mptarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dtype_equal(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, target\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   5816\u001b[0m     \u001b[38;5;66;03m# TODO: if object, could use infer_dtype to preempt costly\u001b[39;00m\n\u001b[0;32m   5817\u001b[0m     \u001b[38;5;66;03m#  conversion if still non-comparable?\u001b[39;00m\n\u001b[0;32m   5818\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_common_type_compat(target)\n",
      "File \u001b[1;32mc:\\Users\\dlaa0001\\Anaconda3\\envs\\popsyn\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5836\u001b[0m, in \u001b[0;36mIndex.get_indexer_non_unique\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   5832\u001b[0m     \u001b[38;5;66;03m# Item \"IndexEngine\" of \"Union[IndexEngine, ExtensionEngine]\" has\u001b[39;00m\n\u001b[0;32m   5833\u001b[0m     \u001b[38;5;66;03m# no attribute \"_extract_level_codes\"\u001b[39;00m\n\u001b[0;32m   5834\u001b[0m     tgt_values \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39m_extract_level_codes(target)  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m-> 5836\u001b[0m indexer, missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_non_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ensure_platform_int(indexer), ensure_platform_int(missing)\n",
      "File \u001b[1;32mc:\\Users\\dlaa0001\\Anaconda3\\envs\\popsyn\\lib\\site-packages\\pandas\\_libs\\index.pyx:835\u001b[0m, in \u001b[0;36mpandas._libs.index.BaseMultiIndexCodesEngine.get_indexer_non_unique\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dlaa0001\\Anaconda3\\envs\\popsyn\\lib\\site-packages\\pandas\\_libs\\index.pyx:440\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer_non_unique\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dlaa0001\\Anaconda3\\envs\\popsyn\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1404\u001b[0m, in \u001b[0;36m_resize_dispatcher\u001b[1;34m(a, new_shape)\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_resize_dispatcher\u001b[39m(a, new_shape):\n\u001b[1;32m-> 1404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Then do rela by rela (HH-Main then Main others and next layers)\n",
    "# Make sure for a given HH/Main/root rela it will exist to have a sample rec\n",
    "\n",
    "# Redo as we are doing it by pairs\n",
    "\n",
    "# to_consider_tags = [\"Main\", \"Child\", \"Parent\", HH_TAG] # Possible root rela, HH last\n",
    "# for tag in to_consider_tags:\n",
    "#     considered_atts = hh_atts if tag == HH_TAG else [f\"{x}_{tag}\" for x in pp_atts]\n",
    "#     related_pool_names = [x for x in pools_ref.keys() if tag in x]\n",
    "#     possible_comb = [] if tag == HH_TAG else [possible_pp_combs]\n",
    "#     for pool_name in related_pool_names:\n",
    "#         print(f\"Processing {pool_name} for {tag}\")\n",
    "#         pool = pools_ref[pool_name].copy(deep=True)\n",
    "#         assert set(considered_atts) <= set(pool.columns)\n",
    "#         converted_pool = pool.set_index(considered_atts)\n",
    "#         possible_comb.append(set(converted_pool.index))\n",
    "#     possible_comb = set.intersection(*possible_comb)\n",
    "#     # update the pool, removing not matched combinations\n",
    "#     for pool_name in related_pool_names:\n",
    "#         pool = pools_ref[pool_name].copy(deep=True)\n",
    "#         converted_pool = pool.set_index(considered_atts)\n",
    "#         pools_ref[pool_name] = converted_pool.loc[list(possible_comb)].reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pools_ref[\"PP\"] = pp_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HH-Main: 2296016\n",
      "Main-Spouse: 2980645\n",
      "Main-Child: 954948\n",
      "Main-Parent: 1431578\n",
      "Main-Sibling: 1104735\n",
      "Main-Others: 2060394\n",
      "Main-Grandchild: 3177627\n",
      "Main-Grandparent: 180154\n",
      "Child-Grandchild: 4399739\n",
      "Parent-Grandparent: 450807\n",
      "HH: 4995294\n",
      "PP: 5000000\n"
     ]
    }
   ],
   "source": [
    "for name, pool in pools_ref.items():\n",
    "    print(f\"{name}: {len(pool)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-check with seed data to ensure it can conver all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can double check again with actual seed data to make sure it is correct (it can cover all data)\n",
    "# NOTE: think about the neg inc, it should exist across all and it should be quite rare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reweight to match the known distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then reweight to match with the seed data, maybe use IPF but we do need to maintain the past distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condense the pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dwelltype</th>\n",
       "      <th>owndwell</th>\n",
       "      <th>hhinc</th>\n",
       "      <th>totalvehs</th>\n",
       "      <th>hhsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358074</th>\n",
       "      <td>Separate House</td>\n",
       "      <td>Fully Owned</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344868</th>\n",
       "      <td>Separate House</td>\n",
       "      <td>Fully Owned</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213636</th>\n",
       "      <td>Separate House</td>\n",
       "      <td>Being Purchased</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>4+</td>\n",
       "      <td>8+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213637</th>\n",
       "      <td>Separate House</td>\n",
       "      <td>Being Purchased</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>4+</td>\n",
       "      <td>8+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426338</th>\n",
       "      <td>Separate House</td>\n",
       "      <td>Being Purchased</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761236</th>\n",
       "      <td>Separate House</td>\n",
       "      <td>Being Purchased</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761237</th>\n",
       "      <td>Separate House</td>\n",
       "      <td>Being Purchased</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4754651</th>\n",
       "      <td>Terrace/Townhouse</td>\n",
       "      <td>Being Purchased</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dwelltype         owndwell            hhinc totalvehs hhsize\n",
       "358074      Separate House      Fully Owned  Negative income         1      3\n",
       "1344868     Separate House      Fully Owned  Negative income         2      2\n",
       "3213636     Separate House  Being Purchased  Negative income        4+     8+\n",
       "3213637     Separate House  Being Purchased  Negative income        4+     8+\n",
       "3426338     Separate House  Being Purchased  Negative income         3      5\n",
       "3761236     Separate House  Being Purchased  Negative income         3      7\n",
       "3761237     Separate House  Being Purchased  Negative income         3      7\n",
       "4754651  Terrace/Townhouse  Being Purchased  Negative income         2      3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pools_ref[\"HH\"][pools_ref[\"HH\"][\"hhinc\"]==\"Negative income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dwelltype</th>\n",
       "      <th>owndwell</th>\n",
       "      <th>hhinc</th>\n",
       "      <th>totalvehs</th>\n",
       "      <th>hhsize</th>\n",
       "      <th>age_Main</th>\n",
       "      <th>sex_Main</th>\n",
       "      <th>persinc_Main</th>\n",
       "      <th>nolicence_Main</th>\n",
       "      <th>anywork_Main</th>\n",
       "      <th>Main</th>\n",
       "      <th>Spouse</th>\n",
       "      <th>Child</th>\n",
       "      <th>Parent</th>\n",
       "      <th>Sibling</th>\n",
       "      <th>Others</th>\n",
       "      <th>Grandchild</th>\n",
       "      <th>Grandparent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166493</th>\n",
       "      <td>Separate House</td>\n",
       "      <td>Fully Owned</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60-69</td>\n",
       "      <td>F</td>\n",
       "      <td>$1000-1249 p.w.</td>\n",
       "      <td>Some Licence</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623149</th>\n",
       "      <td>Separate House</td>\n",
       "      <td>Fully Owned</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>50-59</td>\n",
       "      <td>F</td>\n",
       "      <td>$400-599 p.w.</td>\n",
       "      <td>Some Licence</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483550</th>\n",
       "      <td>Separate House</td>\n",
       "      <td>Being Purchased</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>4+</td>\n",
       "      <td>8+</td>\n",
       "      <td>40-49</td>\n",
       "      <td>F</td>\n",
       "      <td>$300-399 p.w.</td>\n",
       "      <td>Some Licence</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583217</th>\n",
       "      <td>Separate House</td>\n",
       "      <td>Being Purchased</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>40-49</td>\n",
       "      <td>M</td>\n",
       "      <td>$800-999 p.w.</td>\n",
       "      <td>Some Licence</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738240</th>\n",
       "      <td>Separate House</td>\n",
       "      <td>Being Purchased</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>40-49</td>\n",
       "      <td>M</td>\n",
       "      <td>Negative Income</td>\n",
       "      <td>Some Licence</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188906</th>\n",
       "      <td>Terrace/Townhouse</td>\n",
       "      <td>Being Purchased</td>\n",
       "      <td>Negative income</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>50-59</td>\n",
       "      <td>M</td>\n",
       "      <td>$1-199 p.w.</td>\n",
       "      <td>Some Licence</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dwelltype         owndwell            hhinc totalvehs hhsize  \\\n",
       "166493      Separate House      Fully Owned  Negative income         1      3   \n",
       "623149      Separate House      Fully Owned  Negative income         2      2   \n",
       "1483550     Separate House  Being Purchased  Negative income        4+     8+   \n",
       "1583217     Separate House  Being Purchased  Negative income         3      5   \n",
       "1738240     Separate House  Being Purchased  Negative income         3      7   \n",
       "2188906  Terrace/Townhouse  Being Purchased  Negative income         2      3   \n",
       "\n",
       "        age_Main sex_Main     persinc_Main nolicence_Main anywork_Main  Main  \\\n",
       "166493     60-69        F  $1000-1249 p.w.   Some Licence            N     1   \n",
       "623149     50-59        F    $400-599 p.w.   Some Licence            Y     1   \n",
       "1483550    40-49        F    $300-399 p.w.   Some Licence            N     1   \n",
       "1583217    40-49        M    $800-999 p.w.   Some Licence            Y     1   \n",
       "1738240    40-49        M  Negative Income   Some Licence            Y     1   \n",
       "2188906    50-59        M      $1-199 p.w.   Some Licence            N     1   \n",
       "\n",
       "         Spouse  Child  Parent  Sibling  Others  Grandchild  Grandparent  \n",
       "166493        1      1       0        0       0           0            0  \n",
       "623149        0      1       0        0       0           0            0  \n",
       "1483550       0      5       0        0       7           1            0  \n",
       "1583217       1      3       0        0       0           0            0  \n",
       "1738240       1      5       0        0       0           0            0  \n",
       "2188906       1      1       0        0       0           0            0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pools_ref[\"HH-Main\"][pools_ref[\"HH-Main\"][\"hhinc\"]==\"Negative income\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(processed_dir / \"dict_pool_pairs_check_all_condensed.pickle\", \"wb\") as handle:\n",
    "#     pickle.dump(pools_ref, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we condensed them all, we later can pack them out?\n",
    "We will have the sample_col, weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "popsyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
