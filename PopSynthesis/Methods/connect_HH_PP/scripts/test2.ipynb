{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from process_data import HH_ATTS, PP_ATTS, ALL_RELA\n",
    "from PopSynthesis.Methods.BN.utils.learn_BN import learn_struct_BN_score, learn_para_BN\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "from pgmpy.factors.discrete import State\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "import pickle\n",
    "\n",
    "\n",
    "def learn_para_BN_new(model, data_df, state_names):\n",
    "    para_learn = BayesianEstimator(\n",
    "            model=model,\n",
    "            data=data_df,\n",
    "            state_names=state_names\n",
    "        )\n",
    "    ls_CPDs = para_learn.get_parameters(\n",
    "        prior_type='K2'\n",
    "    )\n",
    "    model.add_cpds(*ls_CPDs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def process_combine_df(combine_df):\n",
    "    combine_df[\"hhid\"] = combine_df.index\n",
    "    hh_df = combine_df[HH_ATTS]\n",
    "    all_rela_exist = ALL_RELA.copy()\n",
    "    all_rela_exist.remove(\"Self\")\n",
    "    hh_df[\"hhsize\"] = combine_df[all_rela_exist].sum(axis=1)\n",
    "    pp_cols = PP_ATTS + all_rela_exist\n",
    "    pp_cols.remove(\"relationship\")\n",
    "    pp_cols.remove(\"persid\")\n",
    "    pp_df = combine_df[pp_cols]\n",
    "    return hh_df, pp_df\n",
    "\n",
    "\n",
    "def extra_pp_df(pp_df):\n",
    "    to_drop_cols = [x  for x in pp_df.columns if x in ALL_RELA]\n",
    "    pp_df = pp_df.drop(columns=to_drop_cols)\n",
    "    pp_df[\"relationsip\"] = \"Self\"\n",
    "    return pp_df\n",
    "\n",
    "\n",
    "def get_2_pp_connect_state_names(state_names_base, rela):\n",
    "    new_dict_name = {}\n",
    "    for name in state_names_base:\n",
    "        new_dict_name[f\"{name}_main\"] = state_names_base[name]\n",
    "        new_dict_name[f\"{name}_{rela}\"] = state_names_base[name]\n",
    "    return new_dict_name\n",
    "\n",
    "\n",
    "def inference_model_get(ls_rela, state_names_base):\n",
    "    re_dict = {}\n",
    "    for rela in ls_rela:\n",
    "        df = pd.read_csv(f\"../data/connect_main_{rela}.csv\")\n",
    "        id_cols = [x for x in df.columns if \"hhid\" in x or \"persid\" in x]\n",
    "        df = df.drop(columns=id_cols)\n",
    "        print(f\"Learn BN {rela}\")\n",
    "        rela_state_names = get_2_pp_connect_state_names(state_names_base, rela)\n",
    "        model = learn_struct_BN_score(df, show_struct=False, state_names=rela_state_names)\n",
    "        model = learn_para_BN_new(model, df, state_names=rela_state_names)\n",
    "        re_dict[rela] = BayesianModelSampling(model)\n",
    "    return re_dict\n",
    "\n",
    "\n",
    "def process_rela_connect(main_pp_df, infer_model, rela):\n",
    "    print(f\"Processing the relationship {rela}\")\n",
    "    # Loop through each HH and append\n",
    "    all_cols = [x for x in main_pp_df.columns if x not in ALL_RELA]\n",
    "    all_cols.remove(\"hhid\")\n",
    "    ls_df = []\n",
    "    for i, row in main_pp_df.iterrows():\n",
    "        if i % 100 == 0:\n",
    "            print(f\"DOING PROGRESS: {(i*100)/len(main_pp_df)}%\")\n",
    "        evidences = [State(f\"{name}_main\", row[name]) for name in all_cols]\n",
    "        print(evidences, rela)\n",
    "        syn = infer_model.rejection_sample(evidence=evidences, size=row[rela], show_progress=True)\n",
    "        remove_cols = [x for x in syn.columns if \"_main\" in x]\n",
    "        syn = syn.drop(columns=remove_cols)\n",
    "        if row[rela] > 0:\n",
    "            syn.columns = syn.columns.str.rstrip(f'_{rela}')\n",
    "            syn[\"relationship\"] = rela\n",
    "            syn[\"hhid\"] = row[\"hhid\"]\n",
    "            ls_df.append(syn)\n",
    "    re_df = pd.concat(ls_df)\n",
    "    return re_df\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Import the synthetic with main and households\n",
    "    combine_df = pd.read_csv(r\"..\\output\\SynPop_hh_main_POA.csv\")\n",
    "    # Process the HH and main to have the HH with IDs and People in HH\n",
    "    hh_df, main_pp_df_all = process_combine_df(combine_df)\n",
    "    # Store the HH in df, Store the main in a list to handle later\n",
    "    store_pp_df = extra_pp_df(main_pp_df_all)\n",
    "    ls_df_pp = [store_pp_df]\n",
    "\n",
    "    state_names_pp = None\n",
    "    with open('../data/dict_pp_states.pickle', 'rb') as handle:\n",
    "        state_names_pp = pickle.load(handle)\n",
    "\n",
    "    all_rela_exist = ALL_RELA.copy()\n",
    "    all_rela_exist.remove(\"Self\")\n",
    "\n",
    "    dict_model_inference = inference_model_get(all_rela_exist, state_names_pp)\n",
    "    infer_model = dict_model_inference[\"Spouse\"]\n",
    "    evidences = [State(f\"age_main\", \"100+\")]\n",
    "    syn = infer_model.rejection_sample(evidence=evidences, size=10, show_progress=True)\n",
    "    print(syn)\n",
    "\n",
    "\n",
    "if __name__ ==  \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "popsyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
